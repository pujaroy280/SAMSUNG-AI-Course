{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding Exercise #0702"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Convolutional Neural Network (color images):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hi\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "# Execute the codes in TensorFlow 2.0 without editing those in version 1.x (except for the contrib module).\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.datasets.cifar10 import load_data\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Download the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More information about the dataset can be found [here](https://www.cs.toronto.edu/~kriz/cifar.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = load_data()\n",
    "n_train_size = X_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Take a look at the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data X shape: (50000, 32, 32, 3)\n",
      "Training data y shape: (50000, 1)\n",
      "\n",
      "\n",
      "Testing data X shape: (10000, 32, 32, 3)\n",
      "Testing data y shape: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Images already reshaped as 32x32.\n",
    "# 3 Color channels.\n",
    "# y is not one-hot-encoded yet.\n",
    "print(\"Training data X shape: {}\".format(X_train.shape))\n",
    "print(\"Training data y shape: {}\".format(y_train.shape))\n",
    "print(\"\\n\")\n",
    "print(\"Testing data X shape: {}\".format(X_test.shape))\n",
    "print(\"Testing data y shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i_image= 123                                                        # Image index. You can change it at will.\n",
    "a_single_image= X_train[i_image,:,:,:]\n",
    "plt.imshow(a_single_image)                                          #  Display as a color image.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIN : 1\n",
      "MAX : 243\n"
     ]
    }
   ],
   "source": [
    "# Check for the minimum and maximum pixel value.\n",
    "print(\"MIN : {}\".format(a_single_image.min()))                 \n",
    "print(\"MAX : {}\".format(a_single_image.max())) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3. Data preprocessing: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling.\n",
    "X_train = X_train/255                      \n",
    "X_test = X_test/255                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot-Encoding\n",
    "y = np.concatenate([y_train[:,0],y_test[:,0]],axis=0)\n",
    "y = np.array(pd.get_dummies(y, drop_first=False))               # drop_frist = False for one-hot-encoding\n",
    "y_train = y[:n_train_size,:]\n",
    "y_test = y[n_train_size:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4. Define the hyperparameters and placeholders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "n_epochs  = 50001\n",
    "learn_rate = 0.0001\n",
    "drop_prob = 0.5                                     # For the dropout layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ph = tf.placeholder(tf.float32, [None, 32, 32, 3])      # 'None' means any number of rows (observations or batch_size)\n",
    "y_ph = tf.placeholder(tf.float32,[None, 10])\n",
    "drop_prob_ph = tf.placeholder(tf.float32)                 # The drop probability at the dropout layer is a hyperparameter.          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5. Define the Variables:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The configuration of the first convolution layer is as following:\n",
    "- Kernel height = 7.\n",
    "- Kernel width = 7.\n",
    "- In_chanels = **3 (color)**. \n",
    "- Out_channels = 32 (number of feature maps)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need Variables with the folllowing shapes:\n",
    "- Shape of the weight matrix = [kernel_height, kernel_width, in_channels, out_channels].\n",
    "- Shape of the bias = [out_channels]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables are defined according to the specifications mentioned above.\n",
    "W1 = tf.Variable(initial_value=tf.random_normal([7,7,3,32], mean=0, stddev=0.1))\n",
    "b1 = tf.Variable(initial_value=tf.fill([32], 0.1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The configuration of the second convolution layer is as following: \n",
    "- Kernel height = 7.\n",
    "- Kernel width = 7.\n",
    "- In_chanels = 32 (out_channels from the previous convolution layer). \n",
    "- Out_channels = 64 (number of feature maps)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we need Variables with the folllowing shapes:\n",
    "- Shape of the weight matrix = [kernel_height, kernel_width, in_channels, out_channels].\n",
    "- Shape of the bias = [out_channels]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables are defined according to the specifications mentioned above.\n",
    "W2 = tf.Variable(initial_value=tf.random_normal([7,7,32,64], mean=0, stddev=0.1))\n",
    "b2 = tf.Variable(initial_value=tf.fill([64], 0.1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do the following considerations for the flattened fully connected layer:\n",
    "- We will apply convolution twice with padding and there will be no image size reduction. \n",
    "- We will also apply max pooling twice with stride = 2 (vertically and horizontally). \n",
    "- At each max pooling with stride = 2, the image size is halved. Thus, **(32/2)/2 = 8** will be the size (vertical and horizontal) of the resulting final image.   \n",
    "- In the previous layer there were 64 output channels (feature maps). \n",
    "- Considering all these facts, there should be **8x8x64 = 4096** nodes in the flattened layer. \n",
    "- Finally, we will shrink the output from this layer to 1024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables are defined according to the specifications mentioned above.\n",
    "W3 = tf.Variable(initial_value=tf.random_normal([4096,1024], mean=0, stddev=0.1))\n",
    "b3 = tf.Variable(initial_value=tf.fill([1024], 0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do the following considerations for the final output layer: \n",
    "- There are 1024 nodes to match with the output from the previous layer.\n",
    "- We should shrink the output once more because there are 10 different labels (digits 0~9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables are defined according to the specifications mentioned above.\n",
    "W4 = tf.Variable(initial_value=tf.random_normal([1024,10], mean=0, stddev=0.1))\n",
    "b4 = tf.Variable(initial_value=tf.fill([10], 0.1))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6. Define the deep learning model (CNN): "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation of the arguments:\n",
    "- padding = 'SAME' to apply a padding. padding = 'VALID' to apply no padding. \n",
    "- ksize = [1, kernel_height, kernel_width, 1]\n",
    "- strides = [1, stride_vertical, stride_horizontal,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st Convolution layer\n",
    "y1 = tf.nn.conv2d(X_ph, W1, strides=[1, 1, 1, 1], padding='SAME') + b1\n",
    "conv1 = tf.nn.relu(y1)                             # Apply the ReLu activation function. \n",
    "# 1st Pooling layer\n",
    "pool1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd Convolution layer\n",
    "y2 = tf.nn.conv2d(pool1, W2, strides=[1, 1, 1, 1], padding='SAME') + b2\n",
    "conv2 = tf.nn.relu(y2)                            # Apply the ReLu activation function. \n",
    "# 2nd Pooling layer\n",
    "pool2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattened full layer\n",
    "conv2_flattened = tf.reshape(pool2, [-1,4096])   # 8x8x64 = 4096   \n",
    "y3 = tf.matmul(conv2_flattened, W3) + b3    \n",
    "full_layer = tf.nn.relu(y3)                      # Apply the ReLu activation function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropout layer\n",
    "dropout_layer = tf.nn.dropout(full_layer, rate = drop_prob_ph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output layer\n",
    "y_model = tf.matmul(dropout_layer, W4) + b4      # No activation function. Softmax at the output layer is optional. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.7. Define the loss function and the optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_ph, logits=y_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate = learn_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.8. Training and Testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step = 0   ,   Accuracy = 0.100 \n",
      "\n",
      "Step = 500   ,   Accuracy = 0.255 \n",
      "\n",
      "Step = 1000   ,   Accuracy = 0.312 \n",
      "\n",
      "Step = 1500   ,   Accuracy = 0.338 \n",
      "\n",
      "Step = 2000   ,   Accuracy = 0.373 \n",
      "\n",
      "Step = 2500   ,   Accuracy = 0.394 \n",
      "\n",
      "Step = 3000   ,   Accuracy = 0.408 \n",
      "\n",
      "Step = 3500   ,   Accuracy = 0.428 \n",
      "\n",
      "Step = 4000   ,   Accuracy = 0.433 \n",
      "\n",
      "Step = 4500   ,   Accuracy = 0.446 \n",
      "\n",
      "Step = 5000   ,   Accuracy = 0.443 \n",
      "\n",
      "Step = 5500   ,   Accuracy = 0.449 \n",
      "\n",
      "Step = 6000   ,   Accuracy = 0.456 \n",
      "\n",
      "Step = 6500   ,   Accuracy = 0.478 \n",
      "\n",
      "Step = 7000   ,   Accuracy = 0.480 \n",
      "\n",
      "Step = 7500   ,   Accuracy = 0.471 \n",
      "\n",
      "Step = 8000   ,   Accuracy = 0.484 \n",
      "\n",
      "Step = 8500   ,   Accuracy = 0.501 \n",
      "\n",
      "Step = 9000   ,   Accuracy = 0.509 \n",
      "\n",
      "Step = 9500   ,   Accuracy = 0.507 \n",
      "\n",
      "Step = 10000   ,   Accuracy = 0.477 \n",
      "\n",
      "Step = 10500   ,   Accuracy = 0.513 \n",
      "\n",
      "Step = 11000   ,   Accuracy = 0.525 \n",
      "\n",
      "Step = 11500   ,   Accuracy = 0.526 \n",
      "\n",
      "Step = 12000   ,   Accuracy = 0.530 \n",
      "\n",
      "Step = 12500   ,   Accuracy = 0.531 \n",
      "\n",
      "Step = 13000   ,   Accuracy = 0.545 \n",
      "\n",
      "Step = 13500   ,   Accuracy = 0.538 \n",
      "\n",
      "Step = 14000   ,   Accuracy = 0.546 \n",
      "\n",
      "Step = 14500   ,   Accuracy = 0.550 \n",
      "\n",
      "Step = 15000   ,   Accuracy = 0.547 \n",
      "\n",
      "Step = 15500   ,   Accuracy = 0.558 \n",
      "\n",
      "Step = 16000   ,   Accuracy = 0.560 \n",
      "\n",
      "Step = 16500   ,   Accuracy = 0.553 \n",
      "\n",
      "Step = 17000   ,   Accuracy = 0.572 \n",
      "\n",
      "Step = 17500   ,   Accuracy = 0.563 \n",
      "\n",
      "Step = 18000   ,   Accuracy = 0.573 \n",
      "\n",
      "Step = 18500   ,   Accuracy = 0.564 \n",
      "\n",
      "Step = 19000   ,   Accuracy = 0.580 \n",
      "\n",
      "Step = 19500   ,   Accuracy = 0.567 \n",
      "\n",
      "Step = 20000   ,   Accuracy = 0.579 \n",
      "\n",
      "Step = 20500   ,   Accuracy = 0.584 \n",
      "\n",
      "Step = 21000   ,   Accuracy = 0.590 \n",
      "\n",
      "Step = 21500   ,   Accuracy = 0.584 \n",
      "\n",
      "Step = 22000   ,   Accuracy = 0.586 \n",
      "\n",
      "Step = 22500   ,   Accuracy = 0.599 \n",
      "\n",
      "Step = 23000   ,   Accuracy = 0.596 \n",
      "\n",
      "Step = 23500   ,   Accuracy = 0.599 \n",
      "\n",
      "Step = 24000   ,   Accuracy = 0.598 \n",
      "\n",
      "Step = 24500   ,   Accuracy = 0.607 \n",
      "\n",
      "Step = 25000   ,   Accuracy = 0.594 \n",
      "\n",
      "Step = 25500   ,   Accuracy = 0.603 \n",
      "\n",
      "Step = 26000   ,   Accuracy = 0.604 \n",
      "\n",
      "Step = 26500   ,   Accuracy = 0.611 \n",
      "\n",
      "Step = 27000   ,   Accuracy = 0.614 \n",
      "\n",
      "Step = 27500   ,   Accuracy = 0.608 \n",
      "\n",
      "Step = 28000   ,   Accuracy = 0.603 \n",
      "\n",
      "Step = 28500   ,   Accuracy = 0.607 \n",
      "\n",
      "Step = 29000   ,   Accuracy = 0.615 \n",
      "\n",
      "Step = 29500   ,   Accuracy = 0.620 \n",
      "\n",
      "Step = 30000   ,   Accuracy = 0.610 \n",
      "\n",
      "Step = 30500   ,   Accuracy = 0.604 \n",
      "\n",
      "Step = 31000   ,   Accuracy = 0.621 \n",
      "\n",
      "Step = 31500   ,   Accuracy = 0.623 \n",
      "\n",
      "Step = 32000   ,   Accuracy = 0.624 \n",
      "\n",
      "Step = 32500   ,   Accuracy = 0.622 \n",
      "\n",
      "Step = 33000   ,   Accuracy = 0.633 \n",
      "\n",
      "Step = 33500   ,   Accuracy = 0.631 \n",
      "\n",
      "Step = 34000   ,   Accuracy = 0.628 \n",
      "\n",
      "Step = 34500   ,   Accuracy = 0.633 \n",
      "\n",
      "Step = 35000   ,   Accuracy = 0.636 \n",
      "\n",
      "Step = 35500   ,   Accuracy = 0.629 \n",
      "\n",
      "Step = 36000   ,   Accuracy = 0.633 \n",
      "\n",
      "Step = 36500   ,   Accuracy = 0.631 \n",
      "\n",
      "Step = 37000   ,   Accuracy = 0.633 \n",
      "\n",
      "Step = 37500   ,   Accuracy = 0.627 \n",
      "\n",
      "Step = 38000   ,   Accuracy = 0.631 \n",
      "\n",
      "Step = 38500   ,   Accuracy = 0.639 \n",
      "\n",
      "Step = 39000   ,   Accuracy = 0.642 \n",
      "\n",
      "Step = 39500   ,   Accuracy = 0.641 \n",
      "\n",
      "Step = 40000   ,   Accuracy = 0.648 \n",
      "\n",
      "Step = 40500   ,   Accuracy = 0.642 \n",
      "\n",
      "Step = 41000   ,   Accuracy = 0.637 \n",
      "\n",
      "Step = 41500   ,   Accuracy = 0.638 \n",
      "\n",
      "Step = 42000   ,   Accuracy = 0.647 \n",
      "\n",
      "Step = 42500   ,   Accuracy = 0.637 \n",
      "\n",
      "Step = 43000   ,   Accuracy = 0.642 \n",
      "\n",
      "Step = 43500   ,   Accuracy = 0.622 \n",
      "\n",
      "Step = 44000   ,   Accuracy = 0.646 \n",
      "\n",
      "Step = 44500   ,   Accuracy = 0.642 \n",
      "\n",
      "Step = 45000   ,   Accuracy = 0.642 \n",
      "\n",
      "Step = 45500   ,   Accuracy = 0.653 \n",
      "\n",
      "Step = 46000   ,   Accuracy = 0.647 \n",
      "\n",
      "Step = 46500   ,   Accuracy = 0.646 \n",
      "\n",
      "Step = 47000   ,   Accuracy = 0.640 \n",
      "\n",
      "Step = 47500   ,   Accuracy = 0.630 \n",
      "\n",
      "Step = 48000   ,   Accuracy = 0.644 \n",
      "\n",
      "Step = 48500   ,   Accuracy = 0.650 \n",
      "\n",
      "Step = 49000   ,   Accuracy = 0.651 \n",
      "\n",
      "Step = 49500   ,   Accuracy = 0.651 \n",
      "\n",
      "Step = 50000   ,   Accuracy = 0.649 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for i in range(n_epochs):\n",
    "            idx_rnd = np.random.choice(range(n_train_size),batch_size,replace=False)                         # Random sampling w/o replacement for the batch indices.                \n",
    "            batch_X, batch_y = X_train[idx_rnd,:,:] , y_train[idx_rnd]                                       # Sample a batch!\n",
    "            my_feed = {X_ph:batch_X, y_ph:batch_y, drop_prob_ph:drop_prob}\n",
    "            sess.run(train, feed_dict = my_feed)\n",
    "            if i % 500 == 0:            \n",
    "                correct_predictions = tf.equal(tf.argmax(y_ph, axis=1), tf.argmax(y_model, axis=1))          # In argmax(), axis=1 means horizontal direction.\n",
    "                accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))                          # Recast the Boolean as float32 first. Then calculate the mean.\n",
    "                my_feed = {X_ph:X_test, y_ph:y_test, drop_prob_ph:0.0}                                       # No dropout for testing.\n",
    "                accuracy_value = sess.run(accuracy, feed_dict = my_feed)                              \n",
    "                print(\"Step = {}   ,   Accuracy = {:5.3f} \\n\".format(i, accuracy_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
