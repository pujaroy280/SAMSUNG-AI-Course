{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ef9b0eb",
   "metadata": {},
   "source": [
    "## Coding Exercise #0901"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cb7899f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prati\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:173: UserWarning: A NumPy version >=1.19.5 and <1.27.0 is required for this version of SciPy (detected version 1.18.5)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87d0ee8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_datasets\n",
      "  Downloading tensorflow_datasets-4.9.2-py3-none-any.whl (5.4 MB)\n",
      "Requirement already satisfied: psutil in c:\\users\\prati\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (5.8.0)\n",
      "Collecting etils[enp,epath]>=0.9.0\n",
      "  Downloading etils-1.3.0-py3-none-any.whl (126 kB)\n",
      "Collecting tensorflow-metadata\n",
      "  Downloading tensorflow_metadata-1.13.1-py3-none-any.whl (28 kB)\n",
      "Collecting dm-tree\n",
      "  Downloading dm_tree-0.1.8-cp38-cp38-win_amd64.whl (101 kB)\n",
      "Requirement already satisfied: wrapt in c:\\users\\prati\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (1.12.1)\n",
      "Requirement already satisfied: click in c:\\users\\prati\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (7.1.2)\n",
      "Collecting protobuf>=3.20\n",
      "  Downloading protobuf-4.23.1-cp38-cp38-win_amd64.whl (422 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\prati\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (1.18.5)\n",
      "Requirement already satisfied: absl-py in c:\\users\\prati\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (1.0.0)\n",
      "Collecting importlib-resources\n",
      "  Downloading importlib_resources-5.12.0-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\prati\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (4.59.0)\n",
      "Collecting array-record\n",
      "  Downloading array_record-0.2.0-py38-none-any.whl (3.0 MB)\n",
      "Requirement already satisfied: termcolor in c:\\users\\prati\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (1.1.0)\n",
      "Collecting promise\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "Requirement already satisfied: toml in c:\\users\\prati\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (0.10.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\prati\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (2.25.1)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\prati\\anaconda3\\lib\\site-packages (from etils[enp,epath]>=0.9.0->tensorflow_datasets) (3.7.4.3)\n",
      "Requirement already satisfied: zipp in c:\\users\\prati\\anaconda3\\lib\\site-packages (from etils[enp,epath]>=0.9.0->tensorflow_datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\prati\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\prati\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\prati\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\prati\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (1.26.4)\n",
      "Requirement already satisfied: six in c:\\users\\prati\\anaconda3\\lib\\site-packages (from absl-py->tensorflow_datasets) (1.15.0)\n",
      "Collecting googleapis-common-protos<2,>=1.52.0\n",
      "  Downloading googleapis_common_protos-1.59.0-py2.py3-none-any.whl (223 kB)\n",
      "Building wheels for collected packages: promise\n",
      "  Building wheel for promise (setup.py): started\n",
      "  Building wheel for promise (setup.py): finished with status 'done'\n",
      "  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21494 sha256=569e8b7ce061859b85820e713d06d8a3a962053c16f345a6fdfc358a88b457f7\n",
      "  Stored in directory: c:\\users\\prati\\appdata\\local\\pip\\cache\\wheels\\54\\aa\\01\\724885182f93150035a2a91bce34a12877e8067a97baaf5dc8\n",
      "Successfully built promise\n",
      "Installing collected packages: etils, protobuf, importlib-resources, googleapis-common-protos, tensorflow-metadata, promise, dm-tree, array-record, tensorflow-datasets\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.18.0\n",
      "    Uninstalling protobuf-3.18.0:\n",
      "      Successfully uninstalled protobuf-3.18.0\n",
      "Successfully installed array-record-0.2.0 dm-tree-0.1.8 etils-1.3.0 googleapis-common-protos-1.59.0 importlib-resources-5.12.0 promise-2.3 protobuf-4.23.1 tensorflow-datasets-4.9.2 tensorflow-metadata-1.13.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.3.0 requires gast==0.3.3, but you have gast 0.4.0 which is incompatible.\n",
      "tensorflow 2.3.0 requires scipy==1.4.1, but you have scipy 1.10.1 which is incompatible.\n",
      "tensorflow 2.3.0 requires tensorflow-estimator<2.4.0,>=2.3.0, but you have tensorflow-estimator 2.5.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "# Install tensorflow_datasets.\n",
    "!pip install tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1621aa9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'message_types_by_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-50089f86aba2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Load MNIST datasets.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtfds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_datasets\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[0m_TIMESTAMP_IMPORT_STARTS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mabsl\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogging\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_tfds_logging\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogging\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcall_metadata\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_call_metadata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0metils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepath\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcommunity\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_builder\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBeamBasedBuilder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_builder\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBuilderConfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\community\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;34m\"\"\"Community dataset API.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommunity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhuggingface_wrapper\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmock_builtin_to_use_gfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommunity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhuggingface_wrapper\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmock_huggingface_import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommunity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbuilder_cls_from_module\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\community\\huggingface_wrapper.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0metils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mepath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdataset_builder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdataset_info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdownload\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0metils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mepath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconstants\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdataset_info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdataset_metadata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_info.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlazy_imports_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnaming\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msplits\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msplits_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfeature_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\splits.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0metils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mepath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnaming\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mproto\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mproto_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0munits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\proto\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;34m\"\"\"Public API of the proto package.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdataset_info_generated_pb2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdataset_info_pb2\u001b[0m  \u001b[1;31m# pylint: disable=line-too-long\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfeature_generated_pb2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfeature_pb2\u001b[0m  \u001b[1;31m# pylint: disable=line-too-long\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\proto\\dataset_info_generated_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfeature_generated_pb2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfeature__pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv0\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mschema_pb2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtensorflow__metadata_dot_proto_dot_v0_dot_schema__pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv0\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstatistics_pb2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtensorflow__metadata_dot_proto_dot_v0_dot_statistics__pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\proto\\feature_generated_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     79\u001b[0m )\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m \u001b[0m_builder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBuildMessageAndEnumDescriptors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDESCRIPTOR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[0m_builder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBuildTopDescriptorsAndMessages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDESCRIPTOR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'feature_pb2'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m_descriptor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_USE_C_DESCRIPTORS\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\google\\protobuf\\internal\\builder.py\u001b[0m in \u001b[0;36mBuildMessageAndEnumDescriptors\u001b[1;34m(file_des, module)\u001b[0m\n\u001b[0;32m     62\u001b[0m       \u001b[0mmodule\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mprefix\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0menum_des\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menum_des\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m   \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg_des\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfile_des\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage_types_by_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[0mmodule_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[0mmodule\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmsg_des\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'message_types_by_name'"
     ]
    }
   ],
   "source": [
    "# Load MNIST datasets.\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c93f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters: BUFFER_SIZE to shuffle data, BATCH_SIZE that is mini-batch size, and the number of training epochs.\n",
    "import numpy as np\n",
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc6c4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of times to repeat per epoch.\n",
    "steps_per_epoch = np.ceil(60000 / BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877e9ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that preprocesses the input image and label.\n",
    "def preprocess(item):\n",
    "    image = item['image']\n",
    "    label = item['label']\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32) # Convert to a tf.float32 type as it was originally a 'unit8' type with a range of [0, 255] \n",
    "    return {'image-pixels' : image}, label[... , tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07363f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define two input functions for training and evaluation.\n",
    "def train_input_fn():\n",
    "    datasets = tfds.load(name='mnist', )\n",
    "    mnist_train = datasets['train']\n",
    "\n",
    "    dataset = mnist_train.map(preprocess)\n",
    "    dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    return dataset.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c49ee24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_input_fn():\n",
    "    datasets = tfds.load(name='mnist')\n",
    "    mnist_test = datasets['test']\n",
    "    dataset = mnist_test.map(preprocess).batch(BATCH_SIZE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180af131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a feature column.\n",
    "image_feature_column = tf.feature_column.numeric_column(key='image-pixels', shape=(28*28)) # Make it as a feature column of 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e0becb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After defining an estimator object\n",
    "dnn_classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=[image_feature_column],\n",
    "    hidden_units=[32, 16],\n",
    "    n_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bed76f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training, evaluation, prediction\n",
    "dnn_classifier.train(\n",
    "    input_fn=train_input_fn,\n",
    "    steps=NUM_EPOCHS * steps_per_epoch)\n",
    "\n",
    "eval_result = dnn_classifier.evaluate(\n",
    "    input_fn=eval_input_fn)\n",
    "\n",
    "print(eval_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
