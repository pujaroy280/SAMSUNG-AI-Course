{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NGb9Ptpx9RzR"
   },
   "source": [
    "## Coding Exercise #0713"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "aB7nE36b9RzT"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition  import LatentDirichletAllocation\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Sch8Li89RzU"
   },
   "source": [
    "#### 1. Latent Dirichlet Allocation (LDA):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "iXPnk5ou9RzU"
   },
   "outputs": [],
   "source": [
    "# The data.\n",
    "my_docs = [\"The economic slowdown is becoming more severe\",\n",
    "           \"The movie was simply awesome\",\n",
    "           \"I like cooking my own food\",\n",
    "           \"Samsung is announcing a new technology\",\n",
    "           \"Machine Learning is an example of awesome technology\",\n",
    "           \"All of us were excited at the movie\",\n",
    "           \"We have to do more to reverse the economic slowdown\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "M8I-KgSu9RzU"
   },
   "outputs": [],
   "source": [
    "my_docs = [x.lower() for x in my_docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BwqiwP239RzU"
   },
   "source": [
    "#### 1.1. Create a DTM representation:\n",
    "CountVectorizer() arguments: <br>\n",
    "- *max_features* : maximum number of features (distict words). <br>\n",
    "- *min_df* : The minimum DF. Integer value means count and real number (0~1) means proportion. <br> \n",
    "- *max_df* : The maximum DF. Integer value means count and real number (0~1) means proportion. Helps to filter out the stop words. <br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yxbWGMkf9RzU",
    "outputId": "aad98dc0-b219-46c6-b7f2-2bfb472776cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['announcing',\n",
       " 'awesome',\n",
       " 'economic',\n",
       " 'example',\n",
       " 'excited',\n",
       " 'food',\n",
       " 'learning',\n",
       " 'movie',\n",
       " 'new',\n",
       " 'reverse',\n",
       " 'samsung',\n",
       " 'severe',\n",
       " 'simply',\n",
       " 'slowdown',\n",
       " 'technology']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(max_features = 15, min_df = 1, max_df = 3, stop_words = 'english')\n",
    "X = vectorizer.fit_transform(my_docs)\n",
    "vectorizer.get_feature_names()\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FOqNg1YP9RzU",
    "outputId": "0a943ff3-a739-426a-a769-b53fcd53f6d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7x15 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 20 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show th DTM. \n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6mrXjTAS9RzV",
    "outputId": "955e5584-7542-4663-a06f-2be2a03b965f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 15)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Size of X (=m x n). m = number of documents = 7 & n = number of features.\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xc6_YRxd9RzV",
    "outputId": "05d68269-a43c-4417-85fe-4eb817aa728f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['announcing', 'awesome', 'economic', 'example', 'excited', 'food', 'learning', 'movie', 'new', 'reverse', 'samsung', 'severe', 'simply', 'slowdown', 'technology']\n"
     ]
    }
   ],
   "source": [
    "# View the features.\n",
    "features = vectorizer.get_feature_names()\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OlcrrhJk9RzV"
   },
   "source": [
    "#### 1.2. Apply the LDA: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "iM8jdSPw9RzV"
   },
   "outputs": [],
   "source": [
    "# Get the topics.\n",
    "n_topics = 4\n",
    "lda = LatentDirichletAllocation(n_components=n_topics, random_state=123)\n",
    "my_docs_topic = lda.fit_transform(X)                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SStLdhKG9RzV",
    "outputId": "ff08812b-200e-4dd4-db34-8f2fe4297274"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.80515032, 0.06273478, 0.06255696, 0.06955794],\n",
       "       [0.06455228, 0.06274657, 0.81007434, 0.06262681],\n",
       "       [0.12522103, 0.12571681, 0.62369815, 0.12536402],\n",
       "       [0.05117543, 0.05023664, 0.84846627, 0.05012166],\n",
       "       [0.84833626, 0.05018186, 0.05138822, 0.05009367],\n",
       "       [0.08342836, 0.08363634, 0.74944622, 0.08348908],\n",
       "       [0.06434067, 0.06264053, 0.06253428, 0.81048452]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# row = document, column = topic.\n",
    "my_docs_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PHlxS4dA9RzV",
    "outputId": "46331d0c-5ae9-4a8a-a1ff-4cff94d0aba8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sum along the row has to give 1.\n",
    "my_docs_topic.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WzjEBFVU9RzW"
   },
   "source": [
    "#### 1.3. From each topic, extract the top features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x0EEG5gC9RzW",
    "outputId": "b0232e4e-6e5c-40a4-bd10-6eb2a6701fbe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 15)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_composition = lda.components_\n",
    "topic_composition.shape     # row = topic, column = feature (word)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "skJlAl0z9RzW"
   },
   "outputs": [],
   "source": [
    "n_top = 3\n",
    "for i in range(n_topics):\n",
    "    topic_features = [features[idx] for idx in np.argsort(-topic_composition[i,:])]   # argsort() shows the sorted index.\n",
    "    topic_features_top = topic_features[0:n_top]\n",
    "    if i == 0:\n",
    "        topic_matrix = [topic_features_top]                    # list의 list 만들 준비!\n",
    "    else:\n",
    "        topic_matrix.append(topic_features_top) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Jswsm-e9RzW",
    "outputId": "4daee367-13e2-4983-f7e8-3f04cdd2cb4f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['awesome', 'technology', 'example'],\n",
       " ['food', 'awesome', 'excited'],\n",
       " ['movie', 'announcing', 'new'],\n",
       " ['economic', 'slowdown', 'reverse']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the top features for each topic.\n",
    "topic_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "7kTEjiKL9RzW"
   },
   "outputs": [],
   "source": [
    "# In view of the top features, we can name the topics.\n",
    "topic_names = ['Technology', 'Cuisine', 'Movie','Economy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TbX1Q1-S9RzW"
   },
   "source": [
    "#### 1.4. Label each document with the most predominant topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cVPpcJMP9RzW",
    "outputId": "c4aa694f-65f7-462d-e68a-b1b8390a0c9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1 = Technology\n",
      "Document 2 = Movie\n",
      "Document 3 = Movie\n",
      "Document 4 = Movie\n",
      "Document 5 = Technology\n",
      "Document 6 = Movie\n",
      "Document 7 = Economy\n"
     ]
    }
   ],
   "source": [
    "# The most probable topic is given directly by the LDA output.\n",
    "n_docs = len(my_docs)\n",
    "for i in range(n_docs):\n",
    "    topic_pick = np.argmax(my_docs_topic[i,:])\n",
    "    print(\"Document \" + str(i+1) + \" = \" + topic_names[topic_pick])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lePEHoIG9RzW"
   },
   "source": [
    "**NOTE**: We can notice some inaccuracies."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
